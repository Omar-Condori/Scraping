# üì∞ Proyecto de Web Scraping - El Comercio

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un sistema completo de **web scraping** para extraer noticias del peri√≥dico **El Comercio** (elcomercio.pe), incluyendo la creaci√≥n de una base de datos SQLite y generaci√≥n de reportes en Excel.

## üéØ Objetivos

- Extraer noticias de la p√°gina web de El Comercio
- Clasificar autom√°ticamente las noticias por categor√≠as
- Almacenar los datos en una base de datos SQLite
- Generar reportes en formato Excel
- Crear consultas SQL para an√°lisis de datos

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3.9**
- **Selenium WebDriver** - Para scraping de contenido din√°mico
- **BeautifulSoup4** - Para an√°lisis de HTML
- **SQLite3** - Base de datos relacional
- **Pandas** - Manipulaci√≥n de datos
- **OpenPyXL** - Generaci√≥n de archivos Excel
- **Git** - Control de versiones

## üìÅ Estructura del Proyecto

```
Scraping/
‚îú‚îÄ‚îÄ README.md                                    # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ scraping_elcomercio_simple.py               # Script b√°sico de scraping
‚îú‚îÄ‚îÄ scraping_elcomercio.py                      # Script con filtros de fecha
‚îú‚îÄ‚îÄ scraping_elcomercio_mejorado.py             # Script mejorado con m√∫ltiples selectores
‚îú‚îÄ‚îÄ scraping_elcomercio_con_fechas.py           # Script con extracci√≥n de fechas
‚îú‚îÄ‚îÄ scraping_elcomercio_titulo_categoria.py     # Script con clasificaci√≥n por categor√≠as
‚îú‚îÄ‚îÄ scraping_elcomercio_excel.py                # Script que genera reportes en Excel
‚îú‚îÄ‚îÄ scraping_elcomercio_semana.py               # Script para noticias de la semana
‚îú‚îÄ‚îÄ scraping_elcomercio_contenido.py            # Script con extracci√≥n de contenido completo
‚îú‚îÄ‚îÄ scraping_elcomercio_contenido_mejorado.py   # Script mejorado para contenido
‚îú‚îÄ‚îÄ crear_base_datos_noticias.py                # Script para crear la base de datos
‚îú‚îÄ‚îÄ consultas_sql_noticias.sql                  # Archivo con consultas SQL
‚îú‚îÄ‚îÄ ejecutar_consultas_sql.py                   # Script para ejecutar consultas
‚îú‚îÄ‚îÄ noticias_elcomercio.db                      # Base de datos SQLite
‚îú‚îÄ‚îÄ reporte_profesor.txt                        # Reporte completo para el profesor
‚îî‚îÄ‚îÄ base_datos_noticias_profesor.xlsx           # Datos exportados a Excel
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

```bash
# Instalar dependencias de Python
pip3 install selenium beautifulsoup4 pandas openpyxl

# Instalar ChromeDriver (macOS con Homebrew)
brew install chromedriver
```

### Configuraci√≥n

1. **Clonar el repositorio:**
```bash
git clone git@github.com:Omar-Condori/Scraping.git
cd Scraping
```

2. **Verificar que ChromeDriver est√© instalado:**
```bash
which chromedriver
# Debe mostrar: /opt/homebrew/bin/chromedriver
```

## üìä Uso del Proyecto

### 1. Scraping B√°sico
```bash
python3 scraping_elcomercio_simple.py
```

### 2. Scraping con Categor√≠as
```bash
python3 scraping_elcomercio_titulo_categoria.py
```

### 3. Scraping con Contenido Completo
```bash
python3 scraping_elcomercio_contenido_mejorado.py
```

### 4. Crear Base de Datos
```bash
python3 crear_base_datos_noticias.py
```

### 5. Ejecutar Consultas SQL
```bash
python3 ejecutar_consultas_sql.py
```

## üóÑÔ∏è Base de Datos

### Estructura de Tablas

#### Tabla: `noticias`
- `id` - Identificador √∫nico
- `titulo` - T√≠tulo de la noticia
- `categoria` - Categor√≠a clasificada
- `resumen` - Resumen de la noticia
- `contenido_completo` - Contenido completo del art√≠culo
- `fecha_publicacion` - Fecha de publicaci√≥n
- `fecha_extraccion` - Fecha de extracci√≥n
- `enlace` - URL de la noticia
- `longitud_contenido` - N√∫mero de caracteres
- `selector_utilizado` - Selector CSS utilizado
- `fuente` - Fuente de la noticia

#### Tabla: `categorias`
- `id` - Identificador √∫nico
- `nombre` - Nombre de la categor√≠a
- `descripcion` - Descripci√≥n de la categor√≠a
- `total_noticias` - Contador de noticias

#### Tabla: `estadisticas`
- `id` - Identificador √∫nico
- `fecha_extraccion` - Fecha de extracci√≥n
- `total_noticias` - Total de noticias
- `categorias_unicas` - N√∫mero de categor√≠as √∫nicas
- `promedio_longitud` - Promedio de longitud de contenido
- `noticia_mas_larga` - T√≠tulo de la noticia m√°s larga
- `noticia_mas_corta` - T√≠tulo de la noticia m√°s corta

### Consultas SQL Principales

```sql
-- Ver todas las noticias
SELECT * FROM noticias ORDER BY fecha_publicacion DESC;

-- Contar noticias por categor√≠a
SELECT categoria, COUNT(*) FROM noticias GROUP BY categoria;

-- Noticias m√°s largas
SELECT titulo, longitud_contenido FROM noticias 
ORDER BY longitud_contenido DESC LIMIT 5;

-- Estad√≠sticas generales
SELECT COUNT(*) as total, AVG(longitud_contenido) as promedio 
FROM noticias;
```

## üìà Resultados del Proyecto

### Estad√≠sticas Generales
- **Total de noticias extra√≠das:** 8
- **Categor√≠as identificadas:** 5
- **Promedio de longitud:** 3,584 caracteres
- **Noticia m√°s larga:** 8,003 caracteres
- **Noticia m√°s corta:** 1,145 caracteres

### Distribuci√≥n por Categor√≠as
- **Pol√≠tica:** 2 noticias (promedio: 4,574 caracteres)
- **Mundo:** 2 noticias (promedio: 4,834 caracteres)
- **Entretenimiento:** 2 noticias (promedio: 2,045 caracteres)
- **Econom√≠a:** 1 noticia (2,564 caracteres)
- **Deportes:** 1 noticia (3,200 caracteres)

## üîç Metodolog√≠a

### 1. Web Scraping
- **Selenium WebDriver** para contenido din√°mico
- **BeautifulSoup** para an√°lisis de HTML
- **M√∫ltiples selectores CSS** para robustez
- **Filtrado de contenido** no relevante

### 2. Clasificaci√≥n Autom√°tica
- **Clasificaci√≥n por URL** (rutas de la p√°gina)
- **Clasificaci√≥n por contenido** (palabras clave en t√≠tulos)
- **Priorizaci√≥n** de categor√≠as m√°s espec√≠ficas

### 3. Almacenamiento de Datos
- **Base de datos SQLite** para consultas eficientes
- **Normalizaci√≥n** de datos
- **Relaciones** entre tablas
- **√çndices** para optimizaci√≥n

### 4. Generaci√≥n de Reportes
- **Archivos Excel** con formato profesional
- **M√∫ltiples hojas** de trabajo
- **Estad√≠sticas** y an√°lisis
- **Documentaci√≥n** completa

## üìä Archivos de Salida

### Reportes Generados
- `reporte_elcomercio_YYYYMMDD_HHMMSS.xlsx` - Reporte b√°sico
- `reporte_semanal_elcomercio_YYYYMMDD_HHMMSS.xlsx` - Reporte semanal
- `reporte_contenido_completo_elcomercio_YYYYMMDD_HHMMSS.xlsx` - Reporte con contenido
- `base_datos_noticias_profesor.xlsx` - Datos de la base de datos
- `reporte_profesor.txt` - Reporte completo en texto

### Base de Datos
- `noticias_elcomercio.db` - Base de datos SQLite principal

## üéì Prop√≥sito Acad√©mico

Este proyecto fue desarrollado como **tarea acad√©mica** para demostrar:
- Conocimientos en **web scraping**
- Manejo de **bases de datos relacionales**
- **An√°lisis de datos** con SQL
- **Generaci√≥n de reportes** automatizados
- **Documentaci√≥n** de proyectos t√©cnicos

## üìù Notas T√©cnicas

### Limitaciones
- El scraping depende de la estructura HTML del sitio web
- Los selectores CSS pueden cambiar con actualizaciones del sitio
- El contenido din√°mico requiere JavaScript habilitado

### Mejoras Futuras
- Implementar **scraping distribuido**
- Agregar **an√°lisis de sentimientos**
- Crear **API REST** para consultas
- Implementar **monitoreo** de cambios en el sitio

## üë®‚Äçüíª Autor

**Omar Condori**
- Estudiante de Ingenier√≠a de Sistemas
- Proyecto acad√©mico de Web Scraping

## üìÑ Licencia

Este proyecto es de uso acad√©mico y educativo.

---

**Fecha de creaci√≥n:** 2025-09-05  
**√öltima actualizaci√≥n:** 2025-09-05  
**Versi√≥n:** 1.0.0
