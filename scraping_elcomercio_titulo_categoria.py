from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time
import re
from datetime import datetime

def extraer_categoria_desde_url(url):
    """Extrae la categor√≠a bas√°ndose en la URL de la noticia"""
    
    # Mapeo de URLs a categor√≠as
    categorias_url = {
        '/politica/': 'Pol√≠tica',
        '/economia/': 'Econom√≠a', 
        '/mundo/': 'Mundo',
        '/deportes/': 'Deportes',
        '/espectaculos/': 'Espect√°culos',
        '/tecnologia/': 'Tecnolog√≠a',
        '/sociedad/': 'Sociedad',
        '/cultura/': 'Cultura',
        '/salud/': 'Salud',
        '/educacion/': 'Educaci√≥n',
        '/turismo/': 'Turismo',
        '/gastronomia/': 'Gastronom√≠a',
        '/saltar-intro/': 'Entretenimiento',
        '/noticias/': 'Noticias Generales'
    }
    
    for path, categoria in categorias_url.items():
        if path in url:
            return categoria
    
    return 'Sin categor√≠a'

def extraer_categoria_desde_titulo(titulo):
    """Extrae categor√≠a bas√°ndose en palabras clave del t√≠tulo"""
    
    palabras_clave = {
        'congreso': 'Pol√≠tica',
        'presidente': 'Pol√≠tica', 
        'gobierno': 'Pol√≠tica',
        'ministro': 'Pol√≠tica',
        'elecciones': 'Pol√≠tica',
        'partido': 'Pol√≠tica',
        'd√≥lar': 'Econom√≠a',
        'inflaci√≥n': 'Econom√≠a',
        'empresa': 'Econom√≠a',
        'mercado': 'Econom√≠a',
        'banco': 'Econom√≠a',
        'futbol': 'Deportes',
        'f√∫tbol': 'Deportes',
        'deporte': 'Deportes',
        'mundial': 'Deportes',
        'liga': 'Deportes',
        'pel√≠cula': 'Espect√°culos',
        'serie': 'Espect√°culos',
        'actor': 'Espect√°culos',
        'm√∫sica': 'Espect√°culos',
        'anime': 'Entretenimiento',
        'manga': 'Entretenimiento',
        'temporada': 'Entretenimiento',
        'cap√≠tulo': 'Entretenimiento',
        'covid': 'Salud',
        'salud': 'Salud',
        'hospital': 'Salud',
        'vacuna': 'Salud',
        'terremoto': 'Sociedad',
        'accidente': 'Sociedad',
        'crimen': 'Sociedad',
        'robo': 'Sociedad'
    }
    
    titulo_lower = titulo.lower()
    for palabra, categoria in palabras_clave.items():
        if palabra in titulo_lower:
            return categoria
    
    return None

# Configuraci√≥n de Chrome
chrome_options = Options()
chrome_options.add_argument("--headless=new")  
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

service = Service("/opt/homebrew/bin/chromedriver")
driver = webdriver.Chrome(service=service, options=chrome_options)

try:
    # Abrir p√°gina de √∫ltimas noticias
    print("üîç Accediendo a El Comercio...")
    driver.get("https://elcomercio.pe/ultimas-noticias/")
    time.sleep(8)  # Esperar m√°s tiempo para que cargue todo el contenido
    
    # Obtener el HTML de la p√°gina
    soup = BeautifulSoup(driver.page_source, "html.parser")
    
    print("üì∞ Analizando estructura de la p√°gina...")
    
    # Buscar diferentes tipos de selectores que podr√≠an contener noticias
    selectores_posibles = [
        "article",
        ".story-item",
        ".story-card", 
        ".Card-link",
        ".StoryLink",
        ".stories__item-link",
        "a[href*='/noticias/']",
        "a[href*='/politica/']",
        "a[href*='/economia/']",
        "a[href*='/mundo/']",
        "a[href*='/deportes/']",
        "a[href*='/espectaculos/']",
        ".headline",
        ".title",
        "h1 a",
        "h2 a", 
        "h3 a",
        ".news-item",
        ".noticia"
    ]
    
    noticias_encontradas = []
    
    for selector in selectores_posibles:
        elementos = soup.select(selector)
        if elementos:
            print(f"‚úÖ Selector '{selector}' encontr√≥ {len(elementos)} elementos")
            
            for elem in elementos[:10]:  # Limitar a 10 por selector
                # Buscar enlaces y t√≠tulos
                if elem.name == 'a':
                    enlace = elem.get('href', '')
                    titulo = elem.get_text(strip=True)
                else:
                    enlace_elem = elem.find('a')
                    if enlace_elem:
                        enlace = enlace_elem.get('href', '')
                        titulo = enlace_elem.get_text(strip=True)
                    else:
                        continue
                
                # Filtrar enlaces v√°lidos de noticias
                if (enlace and 
                    ('/noticias/' in enlace or '/politica/' in enlace or 
                     '/economia/' in enlace or '/mundo/' in enlace or
                     '/deportes/' in enlace or '/espectaculos/' in enlace or
                     '/saltar-intro/' in enlace) and
                    titulo and len(titulo) > 10 and
                    not any(palabra in titulo.lower() for palabra in ['publicidad', 'anuncio', 'sponsor', 'cookies'])):
                    
                    # Completar URL si es relativa
                    if enlace.startswith("/"):
                        enlace = "https://elcomercio.pe" + enlace
                    
                    # Determinar categor√≠a
                    categoria_url = extraer_categoria_desde_url(enlace)
                    categoria_titulo = extraer_categoria_desde_titulo(titulo)
                    
                    # Priorizar categor√≠a del t√≠tulo si es m√°s espec√≠fica
                    categoria_final = categoria_titulo if categoria_titulo else categoria_url
                    
                    noticias_encontradas.append({
                        'titulo': titulo,
                        'enlace': enlace,
                        'categoria': categoria_final,
                        'selector': selector
                    })
    
    # Eliminar duplicados bas√°ndose en el t√≠tulo
    noticias_unicas = []
    titulos_vistos = set()
    
    for noticia in noticias_encontradas:
        titulo_normalizado = re.sub(r'[^\w\s]', '', noticia['titulo'].lower())
        if titulo_normalizado not in titulos_vistos:
            titulos_vistos.add(titulo_normalizado)
            noticias_unicas.append(noticia)
    
    # Mostrar las 5 noticias m√°s importantes con t√≠tulo y categor√≠a
    print(f"\nüìä REPORTE DE NOTICIAS CON T√çTULO Y CATEGOR√çA - EL COMERCIO")
    print("=" * 90)
    print(f"Total de noticias encontradas: {len(noticias_unicas)}")
    print("=" * 90)
    
    if noticias_unicas:
        print("\nüî• LAS 5 NOTICIAS M√ÅS IMPORTANTES CON T√çTULO Y CATEGOR√çA:")
        print("-" * 90)
        
        for i, noticia in enumerate(noticias_unicas[:5], 1):
            print(f"\n{i}. üì∞ T√çTULO: {noticia['titulo']}")
            print(f"   üè∑Ô∏è  CATEGOR√çA: {noticia['categoria']}")
            print(f"   üîó ENLACE: {noticia['enlace']}")
            print(f"   üìç SELECTOR: {noticia['selector']}")
            print("-" * 60)
        
        # Mostrar resumen por categor√≠as
        print(f"\nüìà RESUMEN POR CATEGOR√çAS:")
        print("-" * 40)
        categorias_count = {}
        for noticia in noticias_unicas:
            cat = noticia['categoria']
            categorias_count[cat] = categorias_count.get(cat, 0) + 1
        
        for categoria, count in sorted(categorias_count.items(), key=lambda x: x[1], reverse=True):
            print(f"   {categoria}: {count} noticias")
            
    else:
        print("\n‚ùå No se encontraron noticias con los selectores actuales.")
        print("üí° La p√°gina puede haber cambiado su estructura.")

except Exception as e:
    print(f"‚ùå Error: {e}")
    
finally:
    driver.quit()
    print("\n‚úÖ Proceso completado.")
