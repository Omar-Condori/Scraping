#!/usr/bin/env python3
"""
Sistema de An√°lisis de Noticias con Regresi√≥n Log√≠stica y KNN
Implementa comparaci√≥n entre ambos algoritmos de ML
"""

import psycopg2
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import LabelEncoder
import re
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# Descargar recursos de NLTK
try:
    nltk.download('vader_lexicon', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass

class NewsAnalyzerML:
    def __init__(self, db_url="postgresql://omar@localhost:5432/scraping_db"):
        """Inicializar el analizador de noticias con ML"""
        self.db_url = db_url
        self.conn = None
        self.df = None
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        
    def connect_db(self):
        """Conectar a la base de datos PostgreSQL"""
        try:
            self.conn = psycopg2.connect(self.db_url)
            print("‚úÖ Conectado a la base de datos PostgreSQL")
            return True
        except Exception as e:
            print(f"‚ùå Error conectando a la base de datos: {e}")
            return False
    
    def load_data(self):
        """Cargar datos de noticias desde la base de datos"""
        if not self.conn:
            if not self.connect_db():
                return False
        
        query = """
        SELECT 
            id, title, content, description, category, source, 
            "imageUrl", author, "publishedAt", "scrapedAt"
        FROM articles 
        WHERE content IS NOT NULL AND LENGTH(content) > 50
        ORDER BY "scrapedAt" DESC
        """
        
        try:
            self.df = pd.read_sql(query, self.conn)
            print(f"‚úÖ Cargados {len(self.df)} art√≠culos de la base de datos")
            return True
        except Exception as e:
            print(f"‚ùå Error cargando datos: {e}")
            return False
    
    def preprocess_text(self, text):
        """Preprocesar texto para an√°lisis"""
        if pd.isna(text):
            return ""
        
        # Limpiar texto
        text = re.sub(r'[^\w\s]', '', str(text).lower())
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    def extract_features(self):
        """Extraer caracter√≠sticas de los art√≠culos"""
        print("üîç Extrayendo caracter√≠sticas de los art√≠culos...")
        
        # Caracter√≠sticas b√°sicas
        self.df['title_length'] = self.df['title'].str.len()
        self.df['content_length'] = self.df['content'].str.len()
        self.df['has_image'] = ~self.df['imageUrl'].isna()
        self.df['has_description'] = ~self.df['description'].isna()
        self.df['has_author'] = ~self.df['author'].isna()
        
        # Preprocesar texto
        self.df['title_clean'] = self.df['title'].apply(self.preprocess_text)
        self.df['content_clean'] = self.df['content'].apply(self.preprocess_text)
        
        # An√°lisis de sentimientos
        self.df['sentiment_score'] = self.df['content_clean'].apply(
            lambda x: self.sentiment_analyzer.polarity_scores(x)['compound']
        )
        
        # Clasificar sentimientos
        self.df['sentiment'] = self.df['sentiment_score'].apply(
            lambda x: 'positive' if x > 0.1 else 'negative' if x < -0.1 else 'neutral'
        )
        
        print("‚úÖ Caracter√≠sticas extra√≠das exitosamente")
    
    def mide_error(self, model_name, y_pred, y_test):
        """Medir error del modelo"""
        if len(np.unique(y_test)) == 2:  # Clasificaci√≥n binaria
            accuracy = accuracy_score(y_test, y_pred)
            try:
                auc = roc_auc_score(y_test, y_pred)
                print(f"üìä {model_name} - Precisi√≥n: {accuracy:.4f}, AUC: {auc:.4f}")
            except:
                print(f"üìä {model_name} - Precisi√≥n: {accuracy:.4f}")
        else:  # Clasificaci√≥n multiclase
            accuracy = accuracy_score(y_test, y_pred)
            print(f"üìä {model_name} - Precisi√≥n: {accuracy:.4f}")
        return accuracy

class CategoryClassifierML(NewsAnalyzerML):
    """Clasificador autom√°tico de categor√≠as con LR y KNN"""
    
    def train_category_classifiers(self):
        """Entrenar modelos LR y KNN para clasificar categor√≠as"""
        print("\nüéØ CLASIFICACI√ìN AUTOM√ÅTICA DE CATEGOR√çAS (LR vs KNN)")
        print("=" * 60)
        
        # Filtrar art√≠culos con categor√≠as v√°lidas
        df_categorized = self.df[self.df['category'].notna() & (self.df['category'] != 'Noticias')].copy()
        
        if len(df_categorized) < 50:
            print("‚ùå Insuficientes datos categorizados para entrenar")
            return None
        
        # Preparar datos
        X_text = df_categorized['title_clean'] + ' ' + df_categorized['content_clean']
        y = df_categorized['category']
        
        # Vectorizar texto
        X_vectorized = self.vectorizer.fit_transform(X_text)
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X_vectorized, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Entrenar Regresi√≥n Log√≠stica
        print("üîÑ Entrenando Regresi√≥n Log√≠stica...")
        logreg = LogisticRegression(solver='newton-cg', max_iter=1000)
        logreg.fit(X_train, y_train)
        y_pred_lr = logreg.predict(X_test)
        accuracy_lr = self.mide_error('Regresi√≥n Log√≠stica', y_pred_lr, y_test)
        
        # Entrenar KNN
        print("üîÑ Entrenando KNN...")
        knn = KNeighborsClassifier(n_neighbors=10)
        knn.fit(X_train, y_train)
        y_pred_knn = knn.predict(X_test)
        accuracy_knn = self.mide_error('KNN', y_pred_knn, y_test)
        
        print(f"\nüìà Comparaci√≥n de Modelos:")
        print(f"   Regresi√≥n Log√≠stica: {accuracy_lr:.4f}")
        print(f"   KNN: {accuracy_knn:.4f}")
        print(f"   Diferencia: {abs(accuracy_lr - accuracy_knn):.4f}")
        
        print(f"\nüìä Datos del entrenamiento:")
        print(f"   Categor√≠as disponibles: {df_categorized['category'].nunique()}")
        print(f"   Art√≠culos categorizados: {len(df_categorized)}")
        print(f"   Art√≠culos de entrenamiento: {X_train.shape[0]}")
        print(f"   Art√≠culos de prueba: {X_test.shape[0]}")
        
        # Mostrar reporte de clasificaci√≥n para el mejor modelo
        best_model = "Regresi√≥n Log√≠stica" if accuracy_lr >= accuracy_knn else "KNN"
        best_predictions = y_pred_lr if accuracy_lr >= accuracy_knn else y_pred_knn
        
        print(f"\nüìã Reporte de Clasificaci√≥n ({best_model}):")
        print(classification_report(y_test, best_predictions))
        
        return {
            'logreg': logreg,
            'knn': knn,
            'vectorizer': self.vectorizer,
            'accuracies': {'lr': accuracy_lr, 'knn': accuracy_knn},
            'best_model': best_model
        }

class QualityDetectorML(NewsAnalyzerML):
    """Detector de calidad con LR y KNN"""
    
    def train_quality_detectors(self):
        """Entrenar modelos LR y KNN para detectar calidad"""
        print("\nüîç DETECCI√ìN DE CALIDAD DE CONTENIDO (LR vs KNN)")
        print("=" * 60)
        
        # Definir criterios de calidad
        self.df['quality_score'] = 0
        self.df.loc[self.df['content_length'] > 500, 'quality_score'] += 1
        self.df.loc[self.df['has_image'], 'quality_score'] += 1
        self.df.loc[self.df['has_description'], 'quality_score'] += 1
        self.df.loc[self.df['has_author'], 'quality_score'] += 1
        self.df.loc[self.df['title_length'] > 20, 'quality_score'] += 1
        
        # Clasificar calidad (0-2: baja, 3-4: media, 5: alta)
        self.df['quality'] = self.df['quality_score'].apply(
            lambda x: 'alta' if x >= 4 else 'media' if x >= 2 else 'baja'
        )
        
        # Preparar caracter√≠sticas
        features = ['title_length', 'content_length', 'has_image', 'has_description', 'has_author']
        X = self.df[features].fillna(0)
        y = self.df['quality']
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Entrenar Regresi√≥n Log√≠stica
        print("üîÑ Entrenando Regresi√≥n Log√≠stica...")
        logreg = LogisticRegression(solver='newton-cg', max_iter=1000)
        logreg.fit(X_train, y_train)
        y_pred_lr = logreg.predict(X_test)
        accuracy_lr = self.mide_error('Regresi√≥n Log√≠stica', y_pred_lr, y_test)
        
        # Entrenar KNN
        print("üîÑ Entrenando KNN...")
        knn = KNeighborsClassifier(n_neighbors=10)
        knn.fit(X_train, y_train)
        y_pred_knn = knn.predict(X_test)
        accuracy_knn = self.mide_error('KNN', y_pred_knn, y_test)
        
        print(f"\nüìà Comparaci√≥n de Modelos:")
        print(f"   Regresi√≥n Log√≠stica: {accuracy_lr:.4f}")
        print(f"   KNN: {accuracy_knn:.4f}")
        print(f"   Diferencia: {abs(accuracy_lr - accuracy_knn):.4f}")
        
        print(f"\nüìä Distribuci√≥n de calidad:")
        print(self.df['quality'].value_counts())
        
        return {
            'logreg': logreg,
            'knn': knn,
            'accuracies': {'lr': accuracy_lr, 'knn': accuracy_knn},
            'best_model': "Regresi√≥n Log√≠stica" if accuracy_lr >= accuracy_knn else "KNN"
        }

class SentimentAnalyzerML(NewsAnalyzerML):
    """Analizador de sentimientos con LR y KNN"""
    
    def analyze_sentiments_ml(self):
        """Analizar sentimientos con ambos modelos"""
        print("\nüòä AN√ÅLISIS DE SENTIMIENTOS (LR vs KNN)")
        print("=" * 60)
        
        # Preparar datos para clasificaci√≥n binaria (positivo vs no positivo)
        self.df['sentiment_binary'] = self.df['sentiment'].apply(
            lambda x: 1 if x == 'positive' else 0
        )
        
        # Usar caracter√≠sticas de texto y num√©ricas
        X_text = self.df['title_clean'] + ' ' + self.df['content_clean']
        X_vectorized = self.vectorizer.fit_transform(X_text)
        
        # Agregar caracter√≠sticas num√©ricas
        features_numeric = self.df[['title_length', 'content_length', 'sentiment_score']].fillna(0)
        X_combined = np.hstack([X_vectorized.toarray(), features_numeric.values])
        
        y = self.df['sentiment_binary']
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X_combined, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Entrenar Regresi√≥n Log√≠stica
        print("üîÑ Entrenando Regresi√≥n Log√≠stica...")
        logreg = LogisticRegression(solver='newton-cg', max_iter=1000)
        logreg.fit(X_train, y_train)
        y_pred_lr = logreg.predict(X_test)
        y_prob_lr = logreg.predict_proba(X_test)[:, 1]
        accuracy_lr = self.mide_error('Regresi√≥n Log√≠stica', y_pred_lr, y_test)
        
        # Entrenar KNN
        print("üîÑ Entrenando KNN...")
        knn = KNeighborsClassifier(n_neighbors=10)
        knn.fit(X_train, y_train)
        y_pred_knn = knn.predict(X_test)
        y_prob_knn = knn.predict_proba(X_test)[:, 1]
        accuracy_knn = self.mide_error('KNN', y_pred_knn, y_test)
        
        print(f"\nüìà Comparaci√≥n de Modelos:")
        print(f"   Regresi√≥n Log√≠stica: {accuracy_lr:.4f}")
        print(f"   KNN: {accuracy_knn:.4f}")
        print(f"   Diferencia: {abs(accuracy_lr - accuracy_knn):.4f}")
        
        print(f"\nüìä Distribuci√≥n de sentimientos:")
        sentiment_counts = self.df['sentiment'].value_counts()
        print(sentiment_counts)
        
        return {
            'logreg': logreg,
            'knn': knn,
            'accuracies': {'lr': accuracy_lr, 'knn': accuracy_knn},
            'best_model': "Regresi√≥n Log√≠stica" if accuracy_lr >= accuracy_knn else "KNN",
            'sentiment_distribution': sentiment_counts
        }

class EngagementPredictorML(NewsAnalyzerML):
    """Predictor de engagement con LR y KNN"""
    
    def train_engagement_predictors(self):
        """Entrenar modelos LR y KNN para predecir engagement"""
        print("\nüìà PREDICCI√ìN DE ENGAGEMENT (LR vs KNN)")
        print("=" * 60)
        
        # Simular engagement basado en caracter√≠sticas del art√≠culo
        self.df['engagement_score'] = 0
        self.df.loc[self.df['content_length'] > 300, 'engagement_score'] += 1
        self.df.loc[self.df['has_image'], 'engagement_score'] += 1
        self.df.loc[self.df['sentiment_score'] > 0.1, 'engagement_score'] += 1
        self.df.loc[self.df['title_length'] > 30, 'engagement_score'] += 1
        
        # Clasificar engagement
        self.df['engagement'] = self.df['engagement_score'].apply(
            lambda x: 'alto' if x >= 3 else 'medio' if x >= 2 else 'bajo'
        )
        
        # Preparar caracter√≠sticas
        features = ['title_length', 'content_length', 'has_image', 'sentiment_score', 'has_description']
        X = self.df[features].fillna(0)
        y = self.df['engagement']
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Entrenar Regresi√≥n Log√≠stica
        print("üîÑ Entrenando Regresi√≥n Log√≠stica...")
        logreg = LogisticRegression(solver='newton-cg', max_iter=1000)
        logreg.fit(X_train, y_train)
        y_pred_lr = logreg.predict(X_test)
        accuracy_lr = self.mide_error('Regresi√≥n Log√≠stica', y_pred_lr, y_test)
        
        # Entrenar KNN
        print("üîÑ Entrenando KNN...")
        knn = KNeighborsClassifier(n_neighbors=10)
        knn.fit(X_train, y_train)
        y_pred_knn = knn.predict(X_test)
        accuracy_knn = self.mide_error('KNN', y_pred_knn, y_test)
        
        print(f"\nüìà Comparaci√≥n de Modelos:")
        print(f"   Regresi√≥n Log√≠stica: {accuracy_lr:.4f}")
        print(f"   KNN: {accuracy_knn:.4f}")
        print(f"   Diferencia: {abs(accuracy_lr - accuracy_knn):.4f}")
        
        print(f"\nüìä Distribuci√≥n de engagement:")
        print(self.df['engagement'].value_counts())
        
        return {
            'logreg': logreg,
            'knn': knn,
            'accuracies': {'lr': accuracy_lr, 'knn': accuracy_knn},
            'best_model': "Regresi√≥n Log√≠stica" if accuracy_lr >= accuracy_knn else "KNN"
        }

class SourceClassifierML(NewsAnalyzerML):
    """Clasificador de fuentes con LR y KNN"""
    
    def train_source_classifiers(self):
        """Entrenar modelos LR y KNN para clasificar fuentes"""
        print("\nüì∞ CLASIFICACI√ìN DE FUENTES (LR vs KNN)")
        print("=" * 60)
        
        # Filtrar fuentes con suficientes art√≠culos
        source_counts = self.df['source'].value_counts()
        reliable_sources = source_counts[source_counts >= 10].index
        
        df_filtered = self.df[self.df['source'].isin(reliable_sources)].copy()
        
        if len(df_filtered) < 50:
            print("‚ùå Insuficientes datos para clasificar fuentes")
            return None
        
        # Preparar datos
        X_text = df_filtered['title_clean'] + ' ' + df_filtered['content_clean']
        y = df_filtered['source']
        
        # Vectorizar texto
        X_vectorized = self.vectorizer.fit_transform(X_text)
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X_vectorized, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Entrenar Regresi√≥n Log√≠stica
        print("üîÑ Entrenando Regresi√≥n Log√≠stica...")
        logreg = LogisticRegression(solver='newton-cg', max_iter=1000)
        logreg.fit(X_train, y_train)
        y_pred_lr = logreg.predict(X_test)
        accuracy_lr = self.mide_error('Regresi√≥n Log√≠stica', y_pred_lr, y_test)
        
        # Entrenar KNN
        print("üîÑ Entrenando KNN...")
        knn = KNeighborsClassifier(n_neighbors=10)
        knn.fit(X_train, y_train)
        y_pred_knn = knn.predict(X_test)
        accuracy_knn = self.mide_error('KNN', y_pred_knn, y_test)
        
        print(f"\nüìà Comparaci√≥n de Modelos:")
        print(f"   Regresi√≥n Log√≠stica: {accuracy_lr:.4f}")
        print(f"   KNN: {accuracy_knn:.4f}")
        print(f"   Diferencia: {abs(accuracy_lr - accuracy_knn):.4f}")
        
        print(f"\nüìà Fuentes analizadas: {len(reliable_sources)}")
        print(f"üìä Top fuentes por volumen:")
        print(source_counts.head(10))
        
        return {
            'logreg': logreg,
            'knn': knn,
            'vectorizer': self.vectorizer,
            'accuracies': {'lr': accuracy_lr, 'knn': accuracy_knn},
            'best_model': "Regresi√≥n Log√≠stica" if accuracy_lr >= accuracy_knn else "KNN"
        }

def main():
    """Funci√≥n principal para ejecutar an√°lisis comparativo LR vs KNN"""
    print("üöÄ SISTEMA DE AN√ÅLISIS DE NOTICIAS: REGRESI√ìN LOG√çSTICA vs KNN")
    print("=" * 80)
    
    # Inicializar analizador
    analyzer = NewsAnalyzerML()
    
    # Cargar datos
    if not analyzer.load_data():
        return
    
    # Extraer caracter√≠sticas
    analyzer.extract_features()
    
    print(f"\nüìä RESUMEN DE DATOS:")
    print(f"   Total de art√≠culos: {len(analyzer.df)}")
    print(f"   Categor√≠as √∫nicas: {analyzer.df['category'].nunique()}")
    print(f"   Fuentes √∫nicas: {analyzer.df['source'].nunique()}")
    print(f"   Art√≠culos con im√°genes: {analyzer.df['has_image'].sum()}")
    print(f"   Art√≠culos con descripci√≥n: {analyzer.df['has_description'].sum()}")
    
    # Ejecutar an√°lisis comparativos
    results = {}
    
    # 1. Clasificaci√≥n de categor√≠as
    category_classifier = CategoryClassifierML()
    category_classifier.df = analyzer.df.copy()
    results['category'] = category_classifier.train_category_classifiers()
    
    # 2. Detecci√≥n de calidad
    quality_detector = QualityDetectorML()
    quality_detector.df = analyzer.df.copy()
    results['quality'] = quality_detector.train_quality_detectors()
    
    # 3. An√°lisis de sentimientos
    sentiment_analyzer = SentimentAnalyzerML()
    sentiment_analyzer.df = analyzer.df.copy()
    results['sentiment'] = sentiment_analyzer.analyze_sentiments_ml()
    
    # 4. Predicci√≥n de engagement
    engagement_predictor = EngagementPredictorML()
    engagement_predictor.df = analyzer.df.copy()
    results['engagement'] = engagement_predictor.train_engagement_predictors()
    
    # 5. Clasificaci√≥n de fuentes
    source_classifier = SourceClassifierML()
    source_classifier.df = analyzer.df.copy()
    results['sources'] = source_classifier.train_source_classifiers()
    
    # Resumen final
    print("\nüèÜ RESUMEN COMPARATIVO: REGRESI√ìN LOG√çSTICA vs KNN")
    print("=" * 80)
    
    for task, result in results.items():
        if result:
            print(f"\nüìä {task.upper()}:")
            print(f"   Regresi√≥n Log√≠stica: {result['accuracies']['lr']:.4f}")
            print(f"   KNN: {result['accuracies']['knn']:.4f}")
            print(f"   Mejor modelo: {result['best_model']}")
    
    print("\nüéâ AN√ÅLISIS COMPARATIVO COMPLETADO EXITOSAMENTE!")
    print("=" * 80)
    print("üìã Funcionalidades implementadas:")
    print("   1. ‚úÖ Clasificaci√≥n autom√°tica de categor√≠as (LR vs KNN)")
    print("   2. ‚úÖ Detecci√≥n de calidad de contenido (LR vs KNN)")
    print("   3. ‚úÖ An√°lisis de sentimientos (LR vs KNN)")
    print("   4. ‚úÖ Predicci√≥n de engagement (LR vs KNN)")
    print("   5. ‚úÖ Clasificaci√≥n de fuentes (LR vs KNN)")

if __name__ == "__main__":
    main()
